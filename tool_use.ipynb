{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tool定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool import Calculator, Weather, CurrentDay\n",
    "calculator = Calculator()\n",
    "weather = Weather()\n",
    "current_day = CurrentDay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llm 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", openai_api_key=os.environ['OPENAI_API_KEY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么可以帮助你的吗？')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 大模型直接回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='去年营收为13,242,445,241.43元，今年营收为25,432,543,569.42元。\\n\\n同比增长率 = (今年营收 - 去年营收) / 去年营收 × 100%\\n= (25,432,543,569.42 - 13,242,445,241.43) / 13,242,445,241.43 × 100%\\n= 12,190,098,327.99 / 13,242,445,241.43 × 100%\\n≈ 92%\\n\\n所以，今年营收同比增长了大约92%。'\n"
     ]
    }
   ],
   "source": [
    "query = \"去年营收13,242.445,241.43元, 今年营收25,432,543,569.42元, 同比增长了多少？\"\n",
    "resp = llm.invoke(query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.92053228129291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke(\"25,432,543,569.42/13,242,445,241.43\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, tags=['structured-chat-zero-shot-react-description'], agent=StructuredChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math, args: {{\\'para\\': {{\\'title\\': \\'Para\\', \\'type\\': \\'string\\'}}}}\\nWeather: Get the Temperature of given day, args: {{\\'day\\': {{\\'title\\': \\'Day\\', \\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Calculator, Weather\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x105bfd9c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x105c5add0>, model_name='gpt-3.5-turbo-1106', openai_api_key='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', openai_proxy='')), output_parser=StructuredChatOutputParserWithRetries(output_fixing_parser=OutputFixingParser(parser=StructuredChatOutputParser(), retry_chain=LLMChain(prompt=PromptTemplate(input_variables=['completion', 'error', 'instructions'], template='Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x105bfd9c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x105c5add0>, model_name='gpt-3.5-turbo-1106', openai_api_key='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', openai_proxy='')))), allowed_tools=['Calculator', 'Weather']), tools=[Calculator(), Weather()], handle_parsing_errors=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "        [calculator, weather], llm,\n",
    "        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can help you calculate the year-over-year growth in revenue. To do that, I will use the Calculator tool to find the percentage increase in revenue from last year to this year.\n",
      "\n",
      "Action:\n",
      "```{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"((25432543569.42 - 13242445241.43) / 13242445241.43) * 100\"\n",
      "}```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m92.053228129291\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the year-over-year revenue growth to be approximately 92.05%.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The year-over-year revenue growth is approximately 92.05%.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The year-over-year revenue growth is approximately 92.05%.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query=\"上海和北京哪个城市好？\"\n",
    "resp = agent.run(query)\n",
    "# resp = agent.run(\"去年营收13242445245, 今年营收25432543569, 同比增长了多少？\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
